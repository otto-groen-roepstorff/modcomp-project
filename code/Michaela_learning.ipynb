{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(n=2, T=1000, alpha = 0.9, beta = 0.2, gamma = 0.1, lamb0=1, lamb1=5):\n",
    "    #Defining the three possible values of C\n",
    "    ck = np.arange(3)   \n",
    "    \n",
    "    #Gamma matrix for assigning P(C_t | C_{t-1})\n",
    "    Gamma = np.array([[1-gamma, 0, gamma], \n",
    "                      [0, 1-gamma, gamma], \n",
    "                      [beta/2, beta/2, 1-beta]])\n",
    "    \n",
    "    #Creating random variables with probabilities based of the gamma matrix\n",
    "    C_transition = [\n",
    "        stats.rv_discrete(values=(ck,Gamma[0,])),#P(C_t |C_{t-1} = 0)\n",
    "        stats.rv_discrete(values=(ck,Gamma[1,])),#P(C_t |C_{t-1} = 1)\n",
    "        stats.rv_discrete(values=(ck,Gamma[2,])),#P(C_t |C_{t-1} = 2)\n",
    "    ]\n",
    "\n",
    "    #Creating output vector of C's\n",
    "    C = np.zeros(T, np.int64)\n",
    "    #Initializing the C vector\n",
    "    C[0] = 2\n",
    "\n",
    "    #Filling up the C-vector with values\n",
    "    for i in range(T-1):\n",
    "        C[i+1] = C_transition[C[i]].rvs()\n",
    "    \n",
    "    #CPT of Z\n",
    "    Z_given_C = np.array([1-alpha, alpha, 0.5])  #P(Z = 1| C =c)\n",
    "    \n",
    "    #Initializing Z. size=[n,T] specifies we need to create n copies of a series of T simulations\n",
    "    Z = stats.bernoulli(Z_given_C[C]).rvs(size=[n,T])\n",
    "    #input:\n",
    "    '''\n",
    "    [C_1, C_2, ... C_T]\n",
    "    '''\n",
    "    #output: \n",
    "    '''[   \n",
    "        [Z_11, Z_21, Z_31, ... , Z_T1]\n",
    "        [Z_12, Z_22, Z_32, ... , Z_T2]\n",
    "        ...\n",
    "        [Z_1n, Z_2n, Z_3n, ... , Z_Tn]\n",
    "    ]'''\n",
    "\n",
    "    #Initialize X   \n",
    "    X = stats.poisson(np.where(Z, lamb1, lamb0)).rvs()\n",
    "    #input\n",
    "    '''[   \n",
    "        [f(Z_11), f(Z_21), f(Z_31), ... , f(Z_T1)]\n",
    "        [f(Z_12), f(Z_22), f(Z_32), ... , f(Z_T2)]\n",
    "        ...\n",
    "        [f(Z_1n), f(Z_2n), f(Z_3n), ... , f(Z_Tn)]\n",
    "        ]    \n",
    "        where\n",
    "        f(z) = lamb0+(lamb1-lamb0)*z\n",
    "    '''\n",
    "\n",
    "    #output\n",
    "    '''[   \n",
    "        [X_11, X_21, X_31, ... , X_T1]\n",
    "        [X_12, X_22, X_32, ... , X_T2]\n",
    "        ...\n",
    "        [X_1n, X_2n, X_3n, ... , X_Tn]\n",
    "    ]'''\n",
    "\n",
    "    return C,Z,X\n",
    "\n",
    "C, Z, X = sim(n = 2,T=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clique_Beliefs(Xs, alpha = 0.9, beta = 0.2, lambda_p = [1, 5], gamma = 0.1):\n",
    "\n",
    "    Xs = Xs.astype(int)\n",
    "    n = Xs.shape[1]\n",
    "    T = Xs.shape[0]\n",
    "\n",
    "    # Defining clique potentials\n",
    "\n",
    "    psi_L_i = np.array([[1- gamma, 0, gamma], [0, 1-gamma, gamma], [beta/2, beta/2, 1- beta]])             # (C_t, C_{t+1})\n",
    "    psi_L_1 = np.array([psi_L_i[0] * 0, psi_L_i[1] * 0, psi_L_i[2] * 1])                                         # (C_1,C_2)\n",
    "    psi_M = np.array([[alpha, 1-alpha], [1-alpha, alpha], [0.5,0.5]])                                      # (C_t, Z_{ti})\n",
    "    def psi_N(x):                                                                                          # (Z_{ti}, X_{ti})\n",
    "        def func(z):\n",
    "            return np.exp(-lambda_p[z]) * lambda_p[z] ** x / math.factorial(x)\n",
    "        return func\n",
    "    \n",
    "    # Forward pass messages\n",
    "    # Message from N_ti clique to M_ti clique\n",
    "\n",
    "    delta_Nti_Mti_list = np.empty(shape = (T,n,2))   # (t,i,Z_ti)\n",
    "    for t in range(T):\n",
    "        for i in range(n):\n",
    "            for z_val in [0,1]:\n",
    "                # The X's are fixed\n",
    "                delta_Nti_Mti_list[t,i,z_val] = psi_N(Xs[t,i])(z_val) \n",
    "            # Renormalizing in order to avoid underflow\n",
    "            delta_Nti_Mti_list[t, i, :] /= max(delta_Nti_Mti_list[t, i, :])\n",
    "\n",
    "    # Message from M_ti clique to L_t clique\n",
    "    \n",
    "    delta_Mti_Lt_list = np.empty(shape = (T,n,3)) #(t,i,C_t) \n",
    "    for t in range(T):\n",
    "        for i in range(n):\n",
    "            for c_val in range(3):\n",
    "                # Summing out Z_{ti}, leaving a factor of C_t\n",
    "                delta_Mti_Lt_list[t, i, c_val] = sum([psi_M[c_val,z] * delta_Nti_Mti_list[t,i,z] for z in [0, 1]])   \n",
    "            # Renormalizing\n",
    "            delta_Mti_Lt_list[t, i, :] /= max(delta_Mti_Lt_list[t, i, :])\n",
    "\n",
    "    # Message from L_t to L_{t+1} clique\n",
    "\n",
    "    #Initializing        \n",
    "    delta_L_forward_list = np.empty(shape = (T-2,3)) #(t,C_{t+1}) t=1,...,T-1\n",
    "\n",
    "    # Summing out C_{t}, leaving a factor of C_{t+1}\n",
    "    delta_L_forward_list[0,:] = [sum([psi_L_1[c_i,c_i_] * np.prod(delta_Mti_Lt_list[0,:,c_i], axis = 0) \n",
    "                                  for c_i in [0,1,2]]) for c_i_ in [0,1,2]]  \n",
    "\n",
    "    # Renormalizing\n",
    "    delta_L_forward_list[0,:] /= max(delta_L_forward_list[0,:])\n",
    "\n",
    "    for t in range(1,T-2):\n",
    "        for c_i_ in range(3):\n",
    "            # Summing out C_{t}, leaving a factor of C_{t+1}\n",
    "            delta_L_forward_list[t, c_i_] = sum([psi_L_i[c_i,c_i_] * np.prod(delta_Mti_Lt_list[t,:,c_i], axis = 0)\n",
    "                                             * delta_L_forward_list[t-1,c_i] for c_i in [0,1,2]])   \n",
    "        # Renormalizing\n",
    "        delta_L_forward_list[t,:] /= max(delta_L_forward_list[t,:])\n",
    "\n",
    "    # Clique Beliefs and Downward pass\n",
    "        \n",
    "    belief_L_T_minus_1 = np.empty(shape = (3,3))   # (C_{T-1}, C_{T})\n",
    "\n",
    "    # We loop through all $C_{T-1}$\n",
    "    for c_val in [0,1,2]:\n",
    "\n",
    "        # The clique potential\n",
    "        belief_L_T_minus_1[c_val,:] = psi_L_i[c_val,:] * delta_L_forward_list[T-3,c_val] * np.prod(delta_Mti_Lt_list[T-2,:,:], axis = 0)[c_val] * np.prod(delta_Mti_Lt_list[T-1,:,:], axis = 0)\n",
    "\n",
    "    # Normalizing\n",
    "    belief_L_T_minus_1 /= sum(sum(belief_L_T_minus_1))  \n",
    "\n",
    "    # Initializing beliefs (t,C_t,C_{t+1})\n",
    "    beliefs_L_t = np.empty(shape = (T-1,3,3))  \n",
    "\n",
    "    # Defining first belief                                    \n",
    "    beliefs_L_t[T-2,:,:] = belief_L_T_minus_1 \n",
    "\n",
    "    # Initializing messages t=1,...,T-1\n",
    "    delta_L_backward = np.empty(shape = (T-2,3))   #(t, C_{t}) \n",
    "\n",
    "    # Compute delta_L_{t+1} to L_t\n",
    "    for t in range(T-3,-1,-1):                                                       \n",
    "        for c_val in range(3):     \n",
    "            # Summing out C_{t+1}                                                 \n",
    "            delta_L_backward[t,c_val] =  sum([beliefs_L_t[t+1,c_val,c] / delta_L_forward_list[t,c_val] for c in [0,1,2]]) \n",
    "\n",
    "        # Renormalizing        \n",
    "        delta_L_backward[t,:] /= sum(delta_L_backward[t,:])    \n",
    "\n",
    "        for c_val in range(3):\n",
    "            # Calculating beliefs\n",
    "            beliefs_L_t[t, c_val,:] = psi_L_i[c_val,:] * np.prod(delta_Mti_Lt_list[t,:,:], axis = 0)[c_val] * delta_L_backward[t,:]  \n",
    "\n",
    "        # Normalizing beliefs\n",
    "        beliefs_L_t[t,:,:] /= np.sum(np.sum(beliefs_L_t[t,:,:], axis = 1), axis = 0)\n",
    "\n",
    "    delta_Lt_Mti_list = np.empty(shape = (T,n,3)) #(t,n, C_t) t=1,...,T\n",
    "    for t in range(T-1):\n",
    "            for i in range(n):\n",
    "                for c_val in range(3):\n",
    "                    # Summing out C_{t+1}\n",
    "                    delta_Lt_Mti_list[t, i, c_val] = sum([beliefs_L_t[t, c_val, c_plus] / delta_Mti_Lt_list[t, i , c_val]  for c_plus in [0,1,2]])\n",
    "\n",
    "                # Renormalizing\n",
    "                delta_Lt_Mti_list[t,i,:] /= max(delta_Lt_Mti_list[t,i,:]) \n",
    "\n",
    "    # The last clique is special\n",
    "                \n",
    "    for i in range(n): \n",
    "        for c_plus in range(3):\n",
    "            # Summing out C_{T-1}\n",
    "            delta_Lt_Mti_list[T-1, i, c_plus] = sum([beliefs_L_t[T-2, c_val, c_plus] / delta_Mti_Lt_list[T-1 , i, c_plus] for c_val in [0,1,2]])\n",
    "            \n",
    "        # Renormalizing\n",
    "        delta_Lt_Mti_list[T-1,i,:] /= sum(delta_Lt_Mti_list[T-1,i,:]) \n",
    "\n",
    "    # Initializing beliefs (t,i,C_t,Z_{ti})\n",
    "    beliefs_Mti = np.empty(shape = (T,n,3,2)) # (t,i,C_t,Z_{ti})\n",
    "\n",
    "    for t in range(T):\n",
    "        for i in range(n):\n",
    "            for c_val in range(3):\n",
    "                beliefs_Mti[t,i,c_val,:] = [psi_M[c_val,z] * delta_Lt_Mti_list[t,i,c_val] * delta_Nti_Mti_list[t,i,z] for z in [0,1]]\n",
    "\n",
    "            # Normalizing\n",
    "            beliefs_Mti[t,i,:,:] /= sum(sum(beliefs_Mti[t,i,:,:]))         #(t,i,C_t,Z_{ti})\n",
    "    \n",
    "    return beliefs_L_t, beliefs_Mti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_z_t_i_cond_x(beliefs_M, t,i):\n",
    "    return np.sum(beliefs_M[t-1,i-1,:,:], axis = 0)\n",
    "\n",
    "def p_c_t_cond_x(beliefs_L,t):\n",
    "    if t == T:\n",
    "        return np.sum(beliefs_L[t-2,:,:], axis = 0)\n",
    "    return np.sum(beliefs_L[t-1,:,:], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAP(z_p):\n",
    "\n",
    "    # Initialize \n",
    "    z_inf = 0\n",
    " \n",
    "    # Traverse array elements from second\n",
    "    # and compare every element with\n",
    "    # current max\n",
    "    for i in range(1, len(z_p)):\n",
    "        if z_p[i] > z_p[z_inf]:\n",
    "            z_inf = i\n",
    "    return z_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_par(C,Z,X, Print = False):\n",
    "    n = X.shape[0]\n",
    "    T = X.shape[1]\n",
    "\n",
    "    # Estimating lambda's\n",
    "    lambda1 = sum(sum((Z[:,t] * X[:,t] for t in range(T)))) / (sum(sum(Z)))\n",
    "    lambda0 = sum(sum(((np.ones(shape = n)-Z[:,t]) * X[:,t] for t in range(T)))) / (n*T - sum(sum(Z)))\n",
    "\n",
    "    # Indicator functions of C \n",
    "    C_0 = [C[t] == 0 for t in range(T)]\n",
    "    C_1 = [C[t] == 1 for t in range(T)]\n",
    "    C_2 = [C[t] == 2 for t in range(T)]\n",
    "\n",
    "    # Estimating alpha_hat\n",
    "    if (sum(C_1) > 0):\n",
    "        sum1 = sum(sum(Z[i,t] * C_1[t] for i in range(n)) for t in range(T)) / (2 * sum(C_1) * n)\n",
    "    else:\n",
    "        sum1 = 0\n",
    "    if (sum(C_0) > 0):\n",
    "        sum2 = sum(sum((1-Z[i,t]) * C_0[t] for i in range(n)) for t in range(T)) / (2 * sum(C_0) * n)\n",
    "    else:\n",
    "        sum2 = 0\n",
    "    alpha_hat = sum1 + sum2\n",
    "\n",
    "    # Estimating beta hat\n",
    "    beta_hat = sum((C_0[t+1] + C_1[t+1])*C_2[t] for t in range(T-1)) / (sum(C_2[0:T-1]))\n",
    "\n",
    "    # Estimating gamma hat\n",
    "    gamma_hat = sum((C_2[t+1])*(C_1[t]+C_0[t]) for t in range(T-1)) / (sum(C_1[0:T-1]+ C_0[0:T-1]))\n",
    "\n",
    "    if (Print == True):\n",
    "        print(\"lambda0_hat is: \", lambda0, \"\\nlambda1_hat is: \", lambda1, \"\\nalpha_hat is:\", alpha_hat, \"\\nbeta_hat is: \", beta_hat, \"\\ngamme_hat is: \", gamma_hat)\n",
    "    \n",
    "    return lambda0 ,lambda1, alpha_hat, beta_hat, gamma_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM(C, Z, X, alpha = 0.9, beta = 0.2, gamma = 0.1, lamb0=1, lamb1=5, N = 10):\n",
    "\n",
    "    for i in range(N):\n",
    "\n",
    "        T = Z.dim[0]\n",
    "        n = Z.dim[1]\n",
    "\n",
    "        # Inference - infer the most probable C,Z,X values\n",
    "\n",
    "        beliefs_C, beliefs_Z = Clique_Beliefs(Xs = X, alpha = alpha_hat, beta = beta_hat , gamma = gamma_hat, lambda_p = [lambda0, lambda1])\n",
    "\n",
    "        C_most_prob = [MAP(p_c_t_cond_x(beliefs_C,t+1)) for t in range(T)]\n",
    "        Z_most_prob = np.empty(shape = (T,n))\n",
    "        for t in range(T):\n",
    "            Z_most_prob[t,:] = [MAP(p_z_t_i_cond_x(beliefs_Z,t+1,i+1)) for i in range(n)]\n",
    "\n",
    "        # Learning - computing the most probable parameter estimates\n",
    "\n",
    "        lambda0 ,lambda1, alpha_hat, beta_hat, gamma_hat = learn_par(C_most_prob, Z_most_prob, X, Print = False)    \n",
    "\n",
    "    return par_est"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
